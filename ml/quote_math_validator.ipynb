{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e545771a",
   "metadata": {},
   "source": [
    "# Quote Math Validator\n",
    "\n",
    "This notebook validates the pricing math used by the form-builder quote engine.\n",
    "\n",
    "The PHP `QuoteEngine` and JavaScript `quote.js` share the same deterministic formula:\n",
    "\n",
    "```\n",
    "subtotal  = (base_rate * complexity_multiplier) + addon_total\n",
    "range_low  = round(subtotal * 0.9)\n",
    "range_high = round(subtotal * 1.2)\n",
    "```\n",
    "\n",
    "**Goals**\n",
    "1. Load `quote_math_validation.csv` \u2014 2 500+ correct rows + ~360 intentionally broken rows.\n",
    "2. Re-implement the formula in Python and assert it matches the CSV ground truth.\n",
    "3. Train a lightweight `DecisionTreeClassifier` to detect rows where the stored numbers are wrong.\n",
    "4. Expose a single `predict_quote(...)` function that returns `True` when the math checks out.\n",
    "\n",
    "All packages used (`pandas`, `numpy`, `scikit-learn`) are available on the Kaggle free tier with no GPU required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061dc876",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2265620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, classification_report,\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print(\"pandas\", pd.__version__, \"| numpy\", np.__version__)\n",
    "\n",
    "import sklearn; print(\"scikit-learn\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dfbc42",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Dataset\n",
    "\n",
    "`quote_math_validation.csv` was generated by `gen_data.py` which:\n",
    "- Enumerates every `service \u00d7 complexity` pair\n",
    "- Pairs each with no addons, each single addon, every 2-addon combination, every 3-addon combination, and a sample of 4- and 5-addon combinations\n",
    "- Adds ~15% intentionally miscalculated rows (wrong multiplier, wrong range_low, or wrong range_high) labelled `math_correct = 0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f560e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess, sys\n",
    "\n",
    "KAGGLE_BASE = Path(\"/kaggle/input/datasets/crissymoon/quote-math-validation\")\n",
    "KAGGLE_CSV  = KAGGLE_BASE / \"quote_math_validation.csv\"\n",
    "KAGGLE_GEN  = KAGGLE_BASE / \"gen_data.py\"\n",
    "LOCAL_BASE  = Path(\"/kaggle/working\")\n",
    "LOCAL_CSV   = LOCAL_BASE / \"quote_math_validation.csv\"\n",
    "\n",
    "# Priority: Kaggle input dataset -> already-generated local copy -> regenerate now\n",
    "if KAGGLE_CSV.exists():\n",
    "    CSV_PATH = KAGGLE_CSV\n",
    "elif LOCAL_CSV.exists():\n",
    "    CSV_PATH = LOCAL_CSV\n",
    "else:\n",
    "    # Dataset not attached \u2014 regenerate from gen_data.py into /kaggle/working\n",
    "    gen_script = KAGGLE_GEN if KAGGLE_GEN.exists() else Path(__file__).parent / \"gen_data.py\" if \"__file__\" in dir() else None\n",
    "    if gen_script and gen_script.exists():\n",
    "        print(\"Regenerating CSV from gen_data.py ...\")\n",
    "        subprocess.run([sys.executable, str(gen_script)], check=True)\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            \"CSV not found at Kaggle input path and gen_data.py is unavailable.\\n\"\n",
    "            f\"Expected: {KAGGLE_CSV}\\n\"\n",
    "            \"Attach the dataset 'crissymoon/quote-math-validation' to this notebook.\"\n",
    "        )\n",
    "    CSV_PATH = LOCAL_CSV\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"CSV loaded from:\", CSV_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nClass balance:\")\n",
    "print(df[\"math_correct\"].value_counts())\n",
    "print(\"\\nError type distribution:\")\n",
    "print(df[\"error_type\"].value_counts())\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677cdbe8",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e914c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df.isnull().sum().sum() == 0, \"Unexpected nulls -- re-run gen_data.py\"\n",
    "\n",
    "le_service    = LabelEncoder().fit(df[\"service_type\"])\n",
    "le_complexity = LabelEncoder().fit(df[\"complexity\"])\n",
    "\n",
    "df[\"service_enc\"]    = le_service.transform(df[\"service_type\"])\n",
    "df[\"complexity_enc\"] = le_complexity.transform(df[\"complexity\"])\n",
    "\n",
    "print(\"Service classes   :\", list(le_service.classes_))\n",
    "print(\"Complexity classes:\", list(le_complexity.classes_))\n",
    "\n",
    "# Exclude addon_total: it starts with \"addon_\" but belongs in NUM_COLS\n",
    "ADDON_COLS = [c for c in df.columns if c.startswith(\"addon_\") and c != \"addon_total\"]\n",
    "NUM_COLS   = [\"base_rate\", \"complexity_multiplier\", \"addon_total\",\n",
    "              \"subtotal\", \"range_low\", \"range_high\"]\n",
    "CAT_COLS   = [\"service_enc\", \"complexity_enc\"]\n",
    "FEATURES   = CAT_COLS + NUM_COLS + ADDON_COLS\n",
    "TARGET     = \"math_correct\"\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df[TARGET]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain: {len(X_train)}  Test: {len(X_test)}\")\n",
    "print(f\"Train positive rate: {y_train.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee95be96",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "\n",
    "The numeric columns already encode everything the formula uses, but we add three derived features that make the decision boundary trivially learnable for the tree:\n",
    "\n",
    "| Derived feature | Formula |\n",
    "|---|---|\n",
    "| `expected_subtotal` | `base_rate * complexity_multiplier + addon_total` |\n",
    "| `low_delta` | `range_low - round(expected_subtotal * 0.9)` |\n",
    "| `high_delta` | `range_high - round(expected_subtotal * 1.2)` |\n",
    "\n",
    "A correct row has `low_delta == 0` and `high_delta == 0`. The model learns this quickly, but the exercise is still useful for catching float-rounding edge cases or JS/PHP divergence you might introduce later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a8e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_derived(frame):\n",
    "    \"\"\"Add expected_subtotal, low_delta, high_delta to a copy of the frame.\n",
    "    Uses .values to avoid pandas duplicate-label alignment errors.\n",
    "    \"\"\"\n",
    "    f = frame.copy().reset_index(drop=True)\n",
    "    base   = f[\"base_rate\"].values\n",
    "    mult   = f[\"complexity_multiplier\"].values\n",
    "    addons = f[\"addon_total\"].values\n",
    "    low    = f[\"range_low\"].values\n",
    "    high   = f[\"range_high\"].values\n",
    "    exp    = base * mult + addons\n",
    "    f[\"expected_subtotal\"] = exp\n",
    "    f[\"low_delta\"]         = low  - np.round(exp * 0.9)\n",
    "    f[\"high_delta\"]        = high - np.round(exp * 1.2)\n",
    "    return f\n",
    "\n",
    "X_train_fe = add_derived(X_train)\n",
    "X_test_fe  = add_derived(X_test)\n",
    "\n",
    "FEATURES_FE = FEATURES + [\"expected_subtotal\", \"low_delta\", \"high_delta\"]\n",
    "\n",
    "print(\"Features:\", FEATURES_FE)\n",
    "print(\"Train shape:\", X_train_fe[FEATURES_FE].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736d0862",
   "metadata": {},
   "source": [
    "## 5. Build the Lightweight Model\n",
    "\n",
    "A shallow `DecisionTreeClassifier` (`max_depth=5`) is used because:\n",
    "- The pricing formula is entirely deterministic \u2014 a tree of depth 2\u20133 should already reach near-100% accuracy.\n",
    "- It is fast, interpretable, and produces no float precision issues.\n",
    "- It can be serialised to a tiny JSON/dict for use inside the PHP or JS layer if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dac6ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(\n",
    "    max_depth=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    ")\n",
    "\n",
    "print(\"Model:\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6ab6a5",
   "metadata": {},
   "source": [
    "## 6. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2899e8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_fe[FEATURES_FE], y_train)\n",
    "\n",
    "train_acc = accuracy_score(y_train, model.predict(X_train_fe[FEATURES_FE]))\n",
    "print(f\"Training accuracy : {train_acc:.4f}\")\n",
    "print(f\"Tree depth used   : {model.get_depth()}\")\n",
    "print(f\"Leaf nodes        : {model.get_n_leaves()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0d9495",
   "metadata": {},
   "source": [
    "## 7. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890bb80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_fe[FEATURES_FE])\n",
    "\n",
    "print(\"Test set results\")\n",
    "print(\"----------------\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"wrong (0)\", \"correct (1)\"]))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[\"actual: wrong\", \"actual: correct\"],\n",
    "    columns=[\"pred: wrong\", \"pred: correct\"],\n",
    ")\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm_df)\n",
    "\n",
    "print(f\"\\nAccuracy : {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Recall   : {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1       : {f1_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3f3fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importance = pd.Series(model.feature_importances_, index=FEATURES_FE)\n",
    "importance_sorted = importance[importance > 0].sort_values(ascending=False)\n",
    "\n",
    "print(\"Feature importances (non-zero only):\")\n",
    "print(importance_sorted.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3fbae6",
   "metadata": {},
   "source": [
    "## 8. Run Inference on New Form Inputs\n",
    "\n",
    "`predict_quote(...)` mirrors the `QuoteEngine::calculate()` PHP signature.  \n",
    "Pass the raw form values and it returns `True` if the numbers check out, `False` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9055f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_RATES = {\n",
    "    \"web_design\": 1500, \"web_development\": 3500, \"ecommerce\": 4500,\n",
    "    \"software\": 7500, \"ai_web_app\": 9500, \"ai_native_app\": 14000,\n",
    "}\n",
    "COMPLEXITY_MULTIPLIERS = {\n",
    "    \"simple\": 1.0, \"moderate\": 1.4, \"complex\": 2.0, \"custom\": 2.8,\n",
    "}\n",
    "ADDON_RATES = {\n",
    "    \"seo_basic\": 500, \"seo_advanced\": 1200, \"copywriting\": 800,\n",
    "    \"branding\": 1800, \"maintenance\": 1200, \"hosting_setup\": 350,\n",
    "    \"api_integration\": 1500, \"automation\": 2200,\n",
    "}\n",
    "ADDONS_LIST = list(ADDON_RATES.keys())\n",
    "\n",
    "\n",
    "def _build_row(service_type, complexity, addons,\n",
    "               claimed_subtotal, claimed_range_low, claimed_range_high):\n",
    "    \"\"\"Build a single-row DataFrame in the shape the model expects.\"\"\"\n",
    "    base        = BASE_RATES[service_type]\n",
    "    multiplier  = COMPLEXITY_MULTIPLIERS[complexity]\n",
    "    addon_total = sum(ADDON_RATES[a] for a in addons if a in ADDON_RATES)\n",
    "    exp         = base * multiplier + addon_total\n",
    "    row = {\n",
    "        \"service_enc\"          : le_service.transform([service_type])[0],\n",
    "        \"complexity_enc\"       : le_complexity.transform([complexity])[0],\n",
    "        **{f\"addon_{a}\": (1 if a in addons else 0) for a in ADDONS_LIST},\n",
    "        \"base_rate\"            : base,\n",
    "        \"complexity_multiplier\": multiplier,\n",
    "        \"addon_total\"          : addon_total,\n",
    "        \"subtotal\"             : claimed_subtotal,\n",
    "        \"range_low\"            : claimed_range_low,\n",
    "        \"range_high\"           : claimed_range_high,\n",
    "        \"expected_subtotal\"    : exp,\n",
    "        \"low_delta\"            : claimed_range_low  - round(exp * 0.9),\n",
    "        \"high_delta\"           : claimed_range_high - round(exp * 1.2),\n",
    "    }\n",
    "    return pd.DataFrame([row])[FEATURES_FE], base, multiplier, addon_total, exp\n",
    "\n",
    "\n",
    "def predict_quote(\n",
    "    service_type: str,\n",
    "    complexity: str,\n",
    "    addons: list,\n",
    "    claimed_subtotal: int,\n",
    "    claimed_range_low: int,\n",
    "    claimed_range_high: int,\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if the claimed figures match the QuoteEngine formula exactly.\n",
    "    Both the deterministic rule check and the ML model must agree.\n",
    "    Use predict_quote_detail() for confidence score and breakdown.\n",
    "    \"\"\"\n",
    "    return predict_quote_detail(\n",
    "        service_type, complexity, addons,\n",
    "        claimed_subtotal, claimed_range_low, claimed_range_high\n",
    "    )[\"correct\"]\n",
    "\n",
    "\n",
    "def predict_quote_detail(\n",
    "    service_type: str,\n",
    "    complexity: str,\n",
    "    addons: list,\n",
    "    claimed_subtotal: int,\n",
    "    claimed_range_low: int,\n",
    "    claimed_range_high: int,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Returns a dict with:\n",
    "      correct        (bool)   - True only when both rule and model agree it is valid\n",
    "      confidence     (float)  - model probability for the 'correct' class (0.0-1.0)\n",
    "      rule_ok        (bool)   - deterministic formula check\n",
    "      model_ok       (bool)   - ML model prediction\n",
    "      expected       (dict)   - what the correct values should be\n",
    "      deltas         (dict)   - difference between claimed and expected values\n",
    "      error_flags    (list)   - which fields are wrong, empty if all correct\n",
    "    \"\"\"\n",
    "    row_df, base, multiplier, addon_total, exp = _build_row(\n",
    "        service_type, complexity, addons,\n",
    "        claimed_subtotal, claimed_range_low, claimed_range_high\n",
    "    )\n",
    "\n",
    "    expected_subtotal = round(exp)\n",
    "    expected_low      = round(exp * 0.9)\n",
    "    expected_high     = round(exp * 1.2)\n",
    "\n",
    "    rule_ok = (\n",
    "        claimed_subtotal   == expected_subtotal and\n",
    "        claimed_range_low  == expected_low      and\n",
    "        claimed_range_high == expected_high\n",
    "    )\n",
    "\n",
    "    proba     = model.predict_proba(row_df)[0]                 # [p_wrong, p_correct]\n",
    "    confidence = float(proba[1])                               # probability of 'correct'\n",
    "    model_ok  = confidence >= 0.5\n",
    "\n",
    "    error_flags = []\n",
    "    if claimed_subtotal   != expected_subtotal: error_flags.append(\"subtotal\")\n",
    "    if claimed_range_low  != expected_low:      error_flags.append(\"range_low\")\n",
    "    if claimed_range_high != expected_high:     error_flags.append(\"range_high\")\n",
    "\n",
    "    return {\n",
    "        \"correct\"   : rule_ok and model_ok,\n",
    "        \"confidence\": round(confidence, 4),\n",
    "        \"rule_ok\"   : rule_ok,\n",
    "        \"model_ok\"  : model_ok,\n",
    "        \"expected\"  : {\n",
    "            \"subtotal\"  : expected_subtotal,\n",
    "            \"range_low\" : expected_low,\n",
    "            \"range_high\": expected_high,\n",
    "        },\n",
    "        \"deltas\": {\n",
    "            \"subtotal\"  : claimed_subtotal   - expected_subtotal,\n",
    "            \"range_low\" : claimed_range_low  - expected_low,\n",
    "            \"range_high\": claimed_range_high - expected_high,\n",
    "        },\n",
    "        \"error_flags\": error_flags,\n",
    "    }",
    "\n",
    "# --- demo ---\n",
    "_c = predict_quote_detail(\"web_design\", \"simple\", [], 1500, 1350, 1800)\n",
    "_w = predict_quote_detail(\"web_design\", \"simple\", [], 9999, 1350, 1800)\n",
    "print(f\"correct row  confidence={_c['confidence']:.2f}  correct={_c['correct']}\")\n",
    "print(f\"wrong row    confidence={_w['confidence']:.2f}  correct={_w['correct']}  flags={_w['error_flags']}\")\n",
    "print(\"\\npredict_quote() and predict_quote_detail() ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea828ee9",
   "metadata": {},
   "source": [
    "## 6b. Decision Tree Structure\n",
    "\n",
    "Print the rules the trained tree learned. Because the derived features (`low_delta`, `high_delta`) make the boundary trivial, the tree reaches 100% accuracy in very few splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c0bf719f",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "\n",
    "# Print the learned decision rules (truncated to top 4 levels for readability)\n",
    "rules = export_text(\n",
    "    model,\n",
    "    feature_names=FEATURES_FE,\n",
    "    max_depth=4,\n",
    "    spacing=3,\n",
    ")\n",
    "print(rules)\n",
    "\n",
    "# Compact model card\n",
    "print(\"-\" * 52)\n",
    "print(f\"Algorithm   : DecisionTreeClassifier\")\n",
    "print(f\"Max depth   : {model.get_depth()} (limit was 5)\")\n",
    "print(f\"Leaf nodes  : {model.get_n_leaves()}\")\n",
    "print(f\"Features    : {len(FEATURES_FE)}\")\n",
    "print(f\"Train acc   : {accuracy_score(y_train, model.predict(X_train_fe[FEATURES_FE])):.4f}\")\n",
    "print(\"-\" * 52)\n",
    "\n",
    "# Sample prediction table\n",
    "samples = [\n",
    "    (\"web_design\",    \"simple\",   [],              1500,  1350,  1800),\n",
    "    (\"web_design\",    \"simple\",   [],              9999,  1350,  1800),\n",
    "    (\"ecommerce\",     \"moderate\", [\"branding\"],    8100,  7290,  9720),\n",
    "    (\"ai_native_app\", \"custom\",   [\"automation\"],  41200, 37080, 49440),\n",
    "    (\"software\",      \"custom\",   [\"automation\"],  9700,  8730,  11640),\n",
    "    (\"ai_web_app\",    \"complex\",  [\"api_integration\", \"branding\"], 22300, 20070, 26760),\n",
    "]\n",
    "\n",
    "print(f\"\\n{'service':<16} {'complexity':<10} {'subtotal':>9} {'prediction':<12} {'confidence':>10}\")\n",
    "print(\"-\" * 62)\n",
    "for svc, cmp, add, sub, lo, hi in samples:\n",
    "    d = predict_quote_detail(svc, cmp, add, sub, lo, hi)\n",
    "    label = \"CORRECT\" if d[\"correct\"] else \"WRONG\"\n",
    "    print(f\"{svc:<16} {cmp:<10} {sub:>9} {label:<12} {d['confidence']:>10.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199e4edf",
   "metadata": {},
   "source": [
    "## 9. Confidence Scoring and Extended Tests\n",
    "\n",
    "`predict_quote_detail()` returns the model's probability score alongside the rule check, expected values, per-field deltas, and a list of which fields are wrong.\n",
    "\n",
    "The confidence score comes from `predict_proba` \u2014 it is the model's estimated probability that the row is mathematically correct. A score of `1.00` means the tree is certain; anything below `0.50` is classified as wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80af8ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    # --- Correct cases ---\n",
    "    {\n",
    "        \"label\": \"ai_web_app / complex / branding + api\",\n",
    "        \"service_type\": \"ai_web_app\", \"complexity\": \"complex\",\n",
    "        \"addons\": [\"branding\", \"api_integration\"],\n",
    "        \"claimed_subtotal\": 22300, \"claimed_range_low\": 20070, \"claimed_range_high\": 26760,\n",
    "        \"expect_correct\": True,\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"web_design / simple / no addons\",\n",
    "        \"service_type\": \"web_design\", \"complexity\": \"simple\",\n",
    "        \"addons\": [], \"claimed_subtotal\": 1500,\n",
    "        \"claimed_range_low\": 1350, \"claimed_range_high\": 1800,\n",
    "        \"expect_correct\": True,\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"ecommerce / moderate / seo_advanced + branding\",\n",
    "        \"service_type\": \"ecommerce\", \"complexity\": \"moderate\",\n",
    "        \"addons\": [\"seo_advanced\", \"branding\"],\n",
    "        \"claimed_subtotal\": 9300, \"claimed_range_low\": 8370, \"claimed_range_high\": 11160,\n",
    "        \"expect_correct\": True,\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"ai_native_app / custom / all addons\",\n",
    "        \"service_type\": \"ai_native_app\", \"complexity\": \"custom\",\n",
    "        \"addons\": list(ADDON_RATES.keys()),\n",
    "        \"claimed_subtotal\": 48750, \"claimed_range_low\": 43875, \"claimed_range_high\": 58500,\n",
    "        \"expect_correct\": True,\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"software / simple / no addons\",\n",
    "        \"service_type\": \"software\", \"complexity\": \"simple\",\n",
    "        \"addons\": [], \"claimed_subtotal\": 7500,\n",
    "        \"claimed_range_low\": 6750, \"claimed_range_high\": 9000,\n",
    "        \"expect_correct\": True,\n",
    "    },\n",
    "    # --- Wrong cases ---\n",
    "    {\n",
    "        \"label\": \"web_development / moderate / wrong range_high\",\n",
    "        \"service_type\": \"web_development\", \"complexity\": \"moderate\",\n",
    "        \"addons\": [\"seo_basic\"],\n",
    "        \"claimed_subtotal\": 5400, \"claimed_range_low\": 4860, \"claimed_range_high\": 9999,\n",
    "        \"expect_correct\": False,\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"web_design / simple / wrong subtotal\",\n",
    "        \"service_type\": \"web_design\", \"complexity\": \"simple\",\n",
    "        \"addons\": [], \"claimed_subtotal\": 9999,\n",
    "        \"claimed_range_low\": 1350, \"claimed_range_high\": 1800,\n",
    "        \"expect_correct\": False,\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"ecommerce / complex / wrong range_low\",\n",
    "        \"service_type\": \"ecommerce\", \"complexity\": \"complex\",\n",
    "        \"addons\": [\"hosting_setup\"],\n",
    "        \"claimed_subtotal\": 9350, \"claimed_range_low\": 1000, \"claimed_range_high\": 11220,\n",
    "        \"expect_correct\": False,\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"software / custom / wrong multiplier applied\",\n",
    "        \"service_type\": \"software\", \"complexity\": \"custom\",\n",
    "        \"addons\": [\"automation\"],\n",
    "        # correct: 7500*2.8+2200=23200/20880/27840; claimed uses simple (1.0) -> 9700\n",
    "    \"claimed_subtotal\": 9700, \"claimed_range_low\": 8730, \"claimed_range_high\": 11640,\n",
    "        \"expect_correct\": False,\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"ai_web_app / moderate / all three fields off by 1\",\n",
    "        \"service_type\": \"ai_web_app\", \"complexity\": \"moderate\",\n",
    "        \"addons\": [],\n",
    "        \"claimed_subtotal\": 13301, \"claimed_range_low\": 11971, \"claimed_range_high\": 15961,\n",
    "        \"expect_correct\": False,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Run all tests\n",
    "passed = 0\n",
    "failed = 0\n",
    "\n",
    "col_w = [40, 6, 8, 10]\n",
    "header = f\"{'label':<{col_w[0]}} {'conf':>{col_w[1]}} {'result':<{col_w[2]}} {'pass/fail':<{col_w[3]}}\"\n",
    "print(header)\n",
    "print(\"-\" * sum(col_w) + \"-\" * 4)\n",
    "\n",
    "for tc in test_cases:\n",
    "    args = {k: v for k, v in tc.items() if k not in (\"label\", \"expect_correct\")}\n",
    "    detail = predict_quote_detail(**args)\n",
    "\n",
    "    outcome    = \"CORRECT\" if detail[\"correct\"] else \"WRONG\"\n",
    "    test_pass  = detail[\"correct\"] == tc[\"expect_correct\"]\n",
    "    status     = \"PASS\" if test_pass else \"FAIL\"\n",
    "\n",
    "    if test_pass:\n",
    "        passed += 1\n",
    "    else:\n",
    "        failed += 1\n",
    "\n",
    "    conf_str = f\"{detail['confidence']:.2f}\"\n",
    "    print(f\"{tc['label']:<{col_w[0]}} {conf_str:>{col_w[1]}} {outcome:<{col_w[2]}} {status:<{col_w[3]}}\")\n",
    "\n",
    "    if not test_pass or detail[\"error_flags\"]:\n",
    "        if detail[\"error_flags\"]:\n",
    "            print(f\"  wrong fields : {detail['error_flags']}\")\n",
    "        if not test_pass:\n",
    "            print(f\"  expected     : {detail['expected']}\")\n",
    "            print(f\"  deltas       : {detail['deltas']}\")\n",
    "\n",
    "print()\n",
    "print(f\"Results: {passed}/{len(test_cases)} passed, {failed} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b98a88f",
   "metadata": {},
   "source": [
    "## 10. Save the Model\n",
    "\n",
    "Serialise the trained tree, label encoders, and feature list to `/kaggle/working/` so Kaggle exposes them as downloadable output artefacts.\n",
    "\n",
    "The bundle is a single `.pkl` file that can be loaded by the PHP backend or a future API layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "a47b3f61",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_DIR  = Path(\"/kaggle/working\")\n",
    "MODEL_PKL = OUT_DIR / \"quote_math_model.pkl\"\n",
    "\n",
    "bundle = {\n",
    "    \"model\"          : model,\n",
    "    \"le_service\"     : le_service,\n",
    "    \"le_complexity\"  : le_complexity,\n",
    "    \"features\"       : FEATURES_FE,\n",
    "    \"base_rates\"     : BASE_RATES,\n",
    "    \"complexity_mult\": COMPLEXITY_MULTIPLIERS,\n",
    "    \"addon_rates\"    : ADDON_RATES,\n",
    "}\n",
    "\n",
    "with open(MODEL_PKL, \"wb\") as f:\n",
    "    pickle.dump(bundle, f)\n",
    "\n",
    "size_kb = MODEL_PKL.stat().st_size / 1024\n",
    "print(f\"Model saved  : {MODEL_PKL}\")\n",
    "print(f\"File size    : {size_kb:.1f} KB\")\n",
    "print(f\"Tree depth   : {model.get_depth()}\")\n",
    "print(f\"Leaf nodes   : {model.get_n_leaves()}\")\n",
    "print(f\"Features     : {len(FEATURES_FE)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80a078a",
   "metadata": {},
   "source": [
    "## 11. Reload and Verify\n",
    "\n",
    "Load the bundle from disk and run a quick smoke test to confirm the serialised model produces identical predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "ece62615",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "with open(Path(\"/kaggle/working/quote_math_model.pkl\"), \"rb\") as f:\n",
    "    b = pickle.load(f)\n",
    "\n",
    "m2   = b[\"model\"]\n",
    "les  = b[\"le_service\"]\n",
    "lec  = b[\"le_complexity\"]\n",
    "feat = b[\"features\"]\n",
    "BR   = b[\"base_rates\"]\n",
    "CM   = b[\"complexity_mult\"]\n",
    "AR   = b[\"addon_rates\"]\n",
    "AL   = list(AR.keys())\n",
    "\n",
    "\n",
    "def _smoke_predict(service, complexity, addons, sub, lo, hi):\n",
    "    \"\"\"Mirrors predict_quote_detail: rule check AND model must both agree.\"\"\"\n",
    "    base = BR[service]\n",
    "    mult = CM[complexity]\n",
    "    at   = sum(AR[a] for a in addons if a in AR)\n",
    "    exp  = base * mult + at\n",
    "\n",
    "    rule_ok = (\n",
    "        sub == round(exp)       and\n",
    "        lo  == round(exp * 0.9) and\n",
    "        hi  == round(exp * 1.2)\n",
    "    )\n",
    "\n",
    "    row = {\n",
    "        \"service_enc\"          : les.transform([service])[0],\n",
    "        \"complexity_enc\"       : lec.transform([complexity])[0],\n",
    "        **{f\"addon_{a}\": (1 if a in addons else 0) for a in AL},\n",
    "        \"base_rate\"            : base,\n",
    "        \"complexity_multiplier\": mult,\n",
    "        \"addon_total\"          : at,\n",
    "        \"subtotal\"             : sub,\n",
    "        \"range_low\"            : lo,\n",
    "        \"range_high\"           : hi,\n",
    "        \"expected_subtotal\"    : exp,\n",
    "        \"low_delta\"            : lo - round(exp * 0.9),\n",
    "        \"high_delta\"           : hi - round(exp * 1.2),\n",
    "    }\n",
    "    model_ok = m2.predict(pd.DataFrame([row])[feat])[0] == 1\n",
    "    return int(rule_ok and model_ok)\n",
    "\n",
    "\n",
    "smoke = [\n",
    "    # (service, complexity, addons, subtotal, range_low, range_high, expected_label)\n",
    "    # correct rows\n",
    "    (\"web_design\",    \"simple\",   [],             1500,  1350,  1800,  1),\n",
    "    (\"ecommerce\",     \"moderate\", [\"branding\"],   8100,  7290,  9720,  1),\n",
    "    (\"ai_native_app\", \"custom\",   [],             39200, 35280, 47040, 1),\n",
    "    # wrong rows\n",
    "    (\"web_design\",    \"simple\",   [],             9999,  1350,  1800,  0),  # wrong subtotal\n",
    "    (\"software\",      \"custom\",   [\"automation\"], 9700,  8730,  11640, 0),  # wrong multiplier\n",
    "]\n",
    "\n",
    "all_ok = True\n",
    "print(f\"{'service':<16} {'complexity':<10} {'expected':>8} {'got':>5} {'ok':>4}\")\n",
    "print(\"-\" * 50)\n",
    "for svc, cmp, add, sub, lo, hi, expected_label in smoke:\n",
    "    got = _smoke_predict(svc, cmp, add, sub, lo, hi)\n",
    "    ok  = got == expected_label\n",
    "    all_ok = all_ok and ok\n",
    "    print(f\"{svc:<16} {cmp:<10} {expected_label:>8} {got:>5} {'OK' if ok else 'FAIL':>4}\")\n",
    "\n",
    "print()\n",
    "print(\"Reload smoke test:\", \"PASSED\" if all_ok else \"FAILED\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}